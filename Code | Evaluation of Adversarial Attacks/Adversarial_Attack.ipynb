{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXt83eSLxzC6",
        "outputId": "05f83ac0-b47d-40fc-9efd-c4d13e9c2238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "mjUD_y0KzJjH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/csebuetnlp/normalizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5ZCb-2izAhV",
        "outputId": "3eebeea1-3386-41cc-d449-7cec2d7a8811"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/csebuetnlp/normalizer\n",
            "  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-5rmnjanf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer /tmp/pip-req-build-5rmnjanf\n",
            "  Resolved https://github.com/csebuetnlp/normalizer to commit d405944dde5ceeacb7c2fd3245ae2a9dea5f35c9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from normalizer==0.0.1) (2025.11.3)\n",
            "Requirement already satisfied: emoji==1.4.2 in /usr/local/lib/python3.12/dist-packages (from normalizer==0.0.1) (1.4.2)\n",
            "Requirement already satisfied: ftfy==6.0.3 in /usr/local/lib/python3.12/dist-packages (from normalizer==0.0.1) (6.0.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from normalizer import normalize\n",
        "import torch\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/banglabert_sentiment\"\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=MODEL_PATH,\n",
        "    tokenizer=MODEL_PATH,\n",
        "    return_all_scores=True,\n",
        "    device=0\n",
        "    if torch.cuda.is_available()\n",
        "    else -1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_nPjycnzCj5",
        "outputId": "e40415cc-e285-4f7e-c107-2695f2bf608f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\n",
        "    0: \"Neutral\",\n",
        "    1: \"Positive\",\n",
        "    2: \"Negative\"\n",
        "}\n",
        "\n",
        "reverse_label_map = {\n",
        "    \"LABEL_0\": 0,\n",
        "    \"LABEL_1\": 1,\n",
        "    \"LABEL_2\": 2\n",
        "}\n",
        "\n",
        "def predict_with_confidence(text):\n",
        "    text = normalize(text)\n",
        "    outputs = pipe(text)[0]\n",
        "    best = max(outputs, key=lambda x: x['score'])\n",
        "    pred_label = reverse_label_map[best['label']]\n",
        "    confidence = best['score']\n",
        "    return pred_label, confidence"
      ],
      "metadata": {
        "id": "SLEeXURtdnHT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_dataset(df, dataset_name=\"Test Set\"):\n",
        "\n",
        "    results = []\n",
        "    for i in range(len(df)):\n",
        "        text = df.loc[i, \"text\"]\n",
        "        true_label = df.loc[i, \"label\"]\n",
        "        pred_label, confidence = predict_with_confidence(text)\n",
        "\n",
        "        results.append({\n",
        "            \"text\": text,\n",
        "            \"true_label\": true_label,\n",
        "            \"pred_label\": pred_label,\n",
        "            \"confidence\": confidence,\n",
        "            \"correct\": pred_label == true_label\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = results_df[\"correct\"].mean()\n",
        "    avg_confidence = results_df[\"confidence\"].mean()\n",
        "    correct_conf = results_df[results_df[\"correct\"] == True][\"confidence\"].mean()\n",
        "    incorrect_conf = results_df[results_df[\"correct\"] == False][\"confidence\"].mean()\n",
        "\n",
        "    overconfident = results_df[(results_df[\"correct\"] == False) & (results_df[\"confidence\"] >= 0.9)]\n",
        "    overconfidence_rate = len(overconfident) / len(results_df)\n",
        "\n",
        "    low_conf_correct = results_df[(results_df[\"correct\"] == True) & (results_df[\"confidence\"] < 0.6)]\n",
        "    low_confidence_rate = len(low_conf_correct) / len(results_df)\n",
        "\n",
        "    neutral_shift = results_df[\n",
        "        ((results_df[\"true_label\"] == 1) | (results_df[\"true_label\"] == 2)) &\n",
        "        (results_df[\"pred_label\"] == 0)\n",
        "    ]\n",
        "    neutral_shift_rate = len(neutral_shift) / len(results_df)\n",
        "\n",
        "\n",
        "    # Print results\n",
        "    print(f\"{dataset_name.upper()} EVALUATION RESULTS\")\n",
        "    print(f\"Total Samples: {len(results_df)}\")\n",
        "    print()\n",
        "    print(f\"Overall Accuracy: {accuracy*100:.2f}%\")\n",
        "    print(f\"Average Confidence: {avg_confidence:.4f}\")\n",
        "    print(f\"Average Confidence (Correct Predictions): {correct_conf:.4f}\")\n",
        "    print(f\"Average Confidence (Incorrect Predictions): {incorrect_conf:.4f}\")\n",
        "    print(f\"Overconfidence Rate (Wrong + Confidence >= 0.9): {overconfidence_rate*100:.2f}%\")\n",
        "    print(f\"Low Confidence Rate (Correct + Confidence < 0.6): {low_confidence_rate*100:.2f}%\")\n",
        "    print(f\"Neutral Shift Rate: {neutral_shift_rate*100:.2f}%\")"
      ],
      "metadata": {
        "id": "eq_hvwEgduLN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A1"
      ],
      "metadata": {
        "id": "9vuPeX9sqlK8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_df = pd.read_csv(\"a1_adv_test.csv\")\n",
        "adv_df.rename(columns={\"Data\": \"text\", \"Label\": \"label\"}, inplace=True)\n",
        "adv_results = evaluate_dataset(adv_df, dataset_name=\"Sarcasm Injection Attack\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIFZingsePZI",
        "outputId": "6bf417b6-4f6d-4c37-b21d-e0f2fb355d1c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SARCASM INJECTION ATTACK EVALUATION RESULTS\n",
            "Total Samples: 636\n",
            "\n",
            "Overall Accuracy: 52.52%\n",
            "Average Confidence: 0.7993\n",
            "Average Confidence (Correct Predictions): 0.8635\n",
            "Average Confidence (Incorrect Predictions): 0.7284\n",
            "Overconfidence Rate (Wrong + Confidence >= 0.9): 18.24%\n",
            "Low Confidence Rate (Correct + Confidence < 0.6): 3.77%\n",
            "Neutral Shift Rate: 12.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A2"
      ],
      "metadata": {
        "id": "6b3Zrnpkqnqw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_df = pd.read_csv(\"a2_adv_test.csv\")\n",
        "adv_df.rename(columns={\"Data\": \"text\", \"Label\": \"label\"}, inplace=True)\n",
        "adv_results = evaluate_dataset(adv_df, dataset_name=\"Ancholik Substitution Attack\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mple7JF4HnYE",
        "outputId": "0c051f29-94e9-4a85-bf9f-67058cb35fcc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANCHOLIK SUBSTITUTION ATTACK EVALUATION RESULTS\n",
            "Total Samples: 1585\n",
            "\n",
            "Overall Accuracy: 63.97%\n",
            "Average Confidence: 0.8119\n",
            "Average Confidence (Correct Predictions): 0.8440\n",
            "Average Confidence (Incorrect Predictions): 0.7548\n",
            "Overconfidence Rate (Wrong + Confidence >= 0.9): 15.52%\n",
            "Low Confidence Rate (Correct + Confidence < 0.6): 6.50%\n",
            "Neutral Shift Rate: 7.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A3"
      ],
      "metadata": {
        "id": "V6yovTwTqpIC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_df = pd.read_csv(\"a3_adv_test.csv\")\n",
        "adv_df.rename(columns={\"Data\": \"text\", \"Label\": \"label\"}, inplace=True)\n",
        "adv_results = evaluate_dataset(adv_df, dataset_name=\"Bangla-English Mixing Attack\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5SugYySqqes",
        "outputId": "bc16e914-b3ea-421c-afa5-5e988c524d9b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BANGLA-ENGLISH MIXING ATTACK EVALUATION RESULTS\n",
            "Total Samples: 942\n",
            "\n",
            "Overall Accuracy: 67.62%\n",
            "Average Confidence: 0.8060\n",
            "Average Confidence (Correct Predictions): 0.8448\n",
            "Average Confidence (Incorrect Predictions): 0.7247\n",
            "Overconfidence Rate (Wrong + Confidence >= 0.9): 9.77%\n",
            "Low Confidence Rate (Correct + Confidence < 0.6): 6.37%\n",
            "Neutral Shift Rate: 13.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A4"
      ],
      "metadata": {
        "id": "MtnYxH7Kqs0u"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_df = pd.read_csv(\"a4_adv_test.csv\")\n",
        "adv_df.rename(columns={\"Data\": \"text\", \"Label\": \"label\"}, inplace=True)\n",
        "adv_results = evaluate_dataset(adv_df, dataset_name=\"Implicit Negation Attack\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5orZ4W8wqr02",
        "outputId": "00ac694a-44d6-4c4b-9ab5-027e041fd580"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPLICIT NEGATION ATTACK EVALUATION RESULTS\n",
            "Total Samples: 998\n",
            "\n",
            "Overall Accuracy: 69.34%\n",
            "Average Confidence: 0.8057\n",
            "Average Confidence (Correct Predictions): 0.8467\n",
            "Average Confidence (Incorrect Predictions): 0.7130\n",
            "Overconfidence Rate (Wrong + Confidence >= 0.9): 9.12%\n",
            "Low Confidence Rate (Correct + Confidence < 0.6): 7.01%\n",
            "Neutral Shift Rate: 9.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A5"
      ],
      "metadata": {
        "id": "yHGLcFVXqwrE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_df = pd.read_csv(\"a5_adv_test.csv\")\n",
        "adv_df.rename(columns={\"Data\": \"text\", \"Label\": \"label\"}, inplace=True)\n",
        "adv_results = evaluate_dataset(adv_df, dataset_name=\"Discourse Marker Dilution Attack\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8Q8SUgdqueI",
        "outputId": "73276ff0-0eb2-47d6-8c03-b4d46a713b1a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DISCOURSE MARKER DILUTION ATTACK EVALUATION RESULTS\n",
            "Total Samples: 1407\n",
            "\n",
            "Overall Accuracy: 70.65%\n",
            "Average Confidence: 0.8102\n",
            "Average Confidence (Correct Predictions): 0.8419\n",
            "Average Confidence (Incorrect Predictions): 0.7339\n",
            "Overconfidence Rate (Wrong + Confidence >= 0.9): 9.59%\n",
            "Low Confidence Rate (Correct + Confidence < 0.6): 7.04%\n",
            "Neutral Shift Rate: 11.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A6"
      ],
      "metadata": {
        "id": "uiCH53gtqzsD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_df = pd.read_csv(\"a6_adv_test.csv\")\n",
        "adv_df.rename(columns={\"Data\": \"text\", \"Label\": \"label\"}, inplace=True)\n",
        "adv_results = evaluate_dataset(adv_df, dataset_name=\"Emoji Polarity Conflict Attack\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aPv18Meq0u4",
        "outputId": "f3a3b099-e4ea-4b01-d610-dfc93cb124f1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EMOJI POLARITY CONFLICT ATTACK EVALUATION RESULTS\n",
            "Total Samples: 1586\n",
            "\n",
            "Overall Accuracy: 69.36%\n",
            "Average Confidence: 0.8403\n",
            "Average Confidence (Correct Predictions): 0.8677\n",
            "Average Confidence (Incorrect Predictions): 0.7783\n",
            "Overconfidence Rate (Wrong + Confidence >= 0.9): 15.26%\n",
            "Low Confidence Rate (Correct + Confidence < 0.6): 4.98%\n",
            "Neutral Shift Rate: 5.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A7"
      ],
      "metadata": {
        "id": "E-SQzDTBq146"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_df = pd.read_csv(\"a7_adv_test.csv\")\n",
        "adv_df.rename(columns={\"Data\": \"text\", \"Label\": \"label\"}, inplace=True)\n",
        "adv_results = evaluate_dataset(adv_df, dataset_name=\"Opinion Holder Shift Attack\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNFEBxeXq3t4",
        "outputId": "fedbdbe3-9602-4d44-e5e5-ac8afbfbee74"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPINION HOLDER SHIFT ATTACK EVALUATION RESULTS\n",
            "Total Samples: 1500\n",
            "\n",
            "Overall Accuracy: 36.33%\n",
            "Average Confidence: 0.8148\n",
            "Average Confidence (Correct Predictions): 0.8383\n",
            "Average Confidence (Incorrect Predictions): 0.8014\n",
            "Overconfidence Rate (Wrong + Confidence >= 0.9): 35.53%\n",
            "Low Confidence Rate (Correct + Confidence < 0.6): 4.33%\n",
            "Neutral Shift Rate: 15.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A8"
      ],
      "metadata": {
        "id": "eLR1c5qjq4nE"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_df = pd.read_csv(\"a8_adv_test.csv\")\n",
        "adv_df.rename(columns={\"Data\": \"text\", \"Label\": \"label\"}, inplace=True)\n",
        "adv_results = evaluate_dataset(adv_df, dataset_name=\"Metaphor Substitution Attack\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CribOLSq5kv",
        "outputId": "673f147c-b4e3-4c23-c786-d383e63b0a62"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "METAPHOR SUBSTITUTION ATTACK EVALUATION RESULTS\n",
            "Total Samples: 1578\n",
            "\n",
            "Overall Accuracy: 70.28%\n",
            "Average Confidence: 0.8188\n",
            "Average Confidence (Correct Predictions): 0.8539\n",
            "Average Confidence (Incorrect Predictions): 0.7359\n",
            "Overconfidence Rate (Wrong + Confidence >= 0.9): 10.90%\n",
            "Low Confidence Rate (Correct + Confidence < 0.6): 6.84%\n",
            "Neutral Shift Rate: 6.34%\n"
          ]
        }
      ]
    }
  ]
}