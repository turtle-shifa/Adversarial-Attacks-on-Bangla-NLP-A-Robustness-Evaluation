{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPhvAKdL_cXi",
        "outputId": "31d3b221-8406-4021-ced7-a04c2d8a8a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/csebuetnlp/normalizer"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iE0PW3N92SFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN78_5HxzZSk"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from normalizer import normalize\n",
        "\n",
        "model_name = \"csebuetnlp/banglabert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"Train.csv\")\n",
        "df_val = pd.read_csv(\"Val.csv\")\n",
        "df_test = pd.read_csv(\"Test.csv\")\n",
        "\n",
        "for df in [df_train, df_val, df_test]:\n",
        "    df.rename(columns={\"Data\": \"text\", \"Label\": \"label\"}, inplace=True)\n",
        "    df['text'] = df['text'].apply(normalize)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(df_train)\n",
        "val_dataset = Dataset.from_pandas(df_val)\n",
        "test_dataset = Dataset.from_pandas(df_test)\n",
        "\n",
        "print(\"Data loaded and columns renamed successfully.\")"
      ],
      "metadata": {
        "id": "gvK7vb6e2cLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
        "val_tokenized = val_dataset.map(tokenize_function, batched=True)\n",
        "test_tokenized = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "print(\"Tokenization complete.\")"
      ],
      "metadata": {
        "id": "2XMAGJz02h8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "n83uch2p2lNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=val_tokenized,      # Uses validation set during training\n",
        "    compute_metrics=compute_metrics, # Uses our custom accuracy function\n",
        ")\n",
        "\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "print(\"\\nEvaluating on Test Set...\")\n",
        "test_results = trainer.predict(test_tokenized)\n",
        "print(\"Test Set Results:\", test_results.metrics)\n",
        "\n",
        "SAVE_PATH = \"/content/drive/MyDrive/banglabert_sentiment\"\n",
        "\n",
        "model.save_pretrained(SAVE_PATH)\n",
        "tokenizer.save_pretrained(SAVE_PATH)\n",
        "\n",
        "print(\"Model saved to Google Drive successfully.\")"
      ],
      "metadata": {
        "id": "7krKpSVD2q2x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "d2d56f9e-87c8-4ab4-b68f-1286d4a5a110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4716' max='4716' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4716/4716 08:09, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.779600</td>\n",
              "      <td>0.748444</td>\n",
              "      <td>0.706445</td>\n",
              "      <td>0.678621</td>\n",
              "      <td>0.698897</td>\n",
              "      <td>0.706445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.684500</td>\n",
              "      <td>0.697592</td>\n",
              "      <td>0.742183</td>\n",
              "      <td>0.734911</td>\n",
              "      <td>0.732378</td>\n",
              "      <td>0.742183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.495600</td>\n",
              "      <td>0.700047</td>\n",
              "      <td>0.742183</td>\n",
              "      <td>0.737740</td>\n",
              "      <td>0.735166</td>\n",
              "      <td>0.742183</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating on Test Set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Results: {'test_loss': 0.7463292479515076, 'test_accuracy': 0.7238335435056746, 'test_f1': 0.7173617724609864, 'test_precision': 0.7154085994435214, 'test_recall': 0.7238335435056746, 'test_runtime': 4.1175, 'test_samples_per_second': 385.186, 'test_steps_per_second': 48.33}\n",
            "Model saved to Google Drive successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from normalizer import normalize\n",
        "import torch\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/banglabert_sentiment\"\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=MODEL_PATH,\n",
        "    tokenizer=MODEL_PATH,\n",
        "    return_all_scores=True,\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")"
      ],
      "metadata": {
        "id": "QgntaVSd_ZPZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}